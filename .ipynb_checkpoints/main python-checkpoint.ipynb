{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "#import utils\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "from pypathway import GMTUtils\n",
    "\n",
    "import importlib\n",
    "# import pebba_python\n",
    "# importlib.reload(pebba_python)\n",
    "\n",
    "# from pebba_python import *\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from pypathway import ORA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_in = \"data/GSE49757_Septic_vs_Healthy.txt\"\n",
    "gmt_file = \"data/Reactome_2016_15and100Genes.gmt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# funcoes pebba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def pebba(file_in, \n",
    "          gmt_file, \n",
    "          gene_col=\"Gene.symbol\",\n",
    "          logFC_col=\"logFC\",\n",
    "          pvalue_col=\"P.Value\",\n",
    "          min_genes=100,\n",
    "          max_genes=1500,\n",
    "          p_cut=0.2,\n",
    "          verbose=True,\n",
    "          analysis_name= None, \n",
    "          results_dir=\"Results\",\n",
    "          force=False):\n",
    "\n",
    "    validates_inputs(min_genes,max_genes,p_cut)\n",
    "\n",
    "    create_results_directory(results_dir,force)\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    ## Get information from all unique terms\n",
    "    \n",
    "    term2gene , path_desc , merge_p  = read_gmt_hier(gmt_file) #utils.read_gmt_hier(gmt_file)    \n",
    "\n",
    "# alterei funcao pra retornar o merge_p, \n",
    "# ta retornando no formato de vetor mas talvez tenha q mudar para dataframe ou serie\n",
    "    \n",
    "    \n",
    "    \n",
    "    if( isinstance(file_in , str)):\n",
    "        deg_list = pd.read_csv(file_in,  sep = \"\\t\")#header true no original, so tirei o header pra o python inferir\n",
    "        if(analysis_name is None):\n",
    "            analysis_name =   os.path.splitext(os.path.basename(file_in) )[0] # pega o basename e tira a extensao\n",
    "     \n",
    "    elif(isinstance(file_in , pd.DataFrame)):\n",
    "        deg_list = file_in\n",
    "    \n",
    "\n",
    "    if(analysis_name is None):\n",
    "        analysis_name = \"PEBBA_analysis\"\n",
    "    \n",
    "    ## Remove rows that do not have a valid gene symbol\n",
    "    deg_list = deg_list.dropna()\n",
    "    ## Get background genes as a character vector\n",
    "    ## Empty values (non-annotated genes) will be removed\n",
    "    all_genes = deg_list[\"Gene.symbol\"] # passar pra lista?\n",
    "    \n",
    "    # Get cutoff values -------------------------------------------------------\n",
    "    if(verbose):\n",
    "        print(\"Getting cutoff\") # no original era message(), posso usar um print?\n",
    "        \n",
    "    table_cut = _get_cutoff(deg_list, logFC_col, pvalue_col, min_genes, max_genes)\n",
    "    \n",
    "    directions = [\"up\", \"down\" , \"any\"]\n",
    "    \n",
    "    cut_paths =[]\n",
    "    dfs = []\n",
    "    paths = []\n",
    "    for direction in directions:\n",
    "        if (verbose):\n",
    "            print(direction + \"\\nGetting Pathways\")\n",
    "        df , path = _get_pathway(merge_p, term2gene, all_genes,\n",
    "                            deg_list, gene_col, logFC_col,\n",
    "                            pvalue_col, direction,\n",
    "                            min_genes, max_genes, p_cut)\n",
    "        if (verbose):\n",
    "            print(\"Getting Pathway Cutoff\")\n",
    "        \n",
    "        cut_path = _cutoff_path(path, p_cut, direction)\n",
    "        \n",
    "        cut_paths.append(cut_path)\n",
    "        dfs.append(df)\n",
    "        paths.append(path)\n",
    "    \n",
    "    \n",
    "    ## Save heatmaps\n",
    "    if(verbose):\n",
    "        print(\"Saving heatmaps\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [
     0
    ],
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "def validates_inputs(min_genes,max_genes,p_cut):\n",
    "\n",
    "    if(min_genes < 50 or min_genes > 2900):\n",
    "        sys.exit(\"Variable min_genes must be between 50 and 2900 genes\")\n",
    "          \n",
    "    if(max_genes < 100 or max_genes > 3000):\n",
    "        sys.exit(\"Variable max_genes must be between 100 and 3000 genes\")  \n",
    "    \n",
    "    if(p_cut < 0.00001 or p_cut > 1):\n",
    "        sys.exit(\"Variable p_cut must be between 0.00001 and 1\")       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [
     0
    ],
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "def create_results_directory(results_dir,force):\n",
    "    results_dir = os.path.abspath(results_dir)\n",
    "    if not os.path.exists(results_dir): \n",
    "        os.makedirs(\"Results/Tables\") \n",
    "        os.makedirs(\"Results/Heatmaps\")      \n",
    "    else:    \n",
    "        if( not force): \n",
    "            sys.exit(\"Stopping analysis: \", results_dir, \" already exists! Use force=True to overwrite.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read_gmt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "def read_gmt_hier(file_name):\n",
    "    '''\n",
    "    file_name string -> dataframe and dictionary\n",
    "    \n",
    "    Reads .gmt file and returns a Pandas DataFrame and a dictionary with the information of the gmt file in a format ready to be used.\n",
    "    \n",
    "    '''\n",
    "    gmt_names = []\n",
    "    gmt_desc  = []\n",
    "    gmt_genes = []\n",
    "    res =pd.DataFrame()\n",
    "\n",
    "    with open(file_name, 'r') as f:\n",
    "        # separar cada elemento separado por tab e guardar eles\n",
    "        for line in f:\n",
    "            gmt_names.append(line.split(\"\\t\")[0])\n",
    "            gmt_desc.append(line.split(\"\\t\")[1])\n",
    "            gmt_genes.append(line.split(\"\\t\")[2:])\n",
    "\n",
    "    for i in range(len(gmt_genes)) :\n",
    "\n",
    "        # apagar \\n presente no ultimo gene de cada lista (artefato da leitura do arquivo)\n",
    "        gmt_genes[i][-1] = gmt_genes[i][-1].replace(\"\\n\", \"\")\n",
    "\n",
    "        # Poem na forma de um dataframe, cada linha um gene e suas informações relativas \n",
    "        temp= pd.DataFrame({'term': [gmt_names[i]]*len(gmt_genes[i]), 'hier':  [gmt_desc[i]]*len(gmt_genes[i]), 'gene' : gmt_genes[i] })\n",
    "        res = pd.concat([res,temp])\n",
    "\n",
    "    # reseta o indice\n",
    "    res = res.reset_index(drop=True)    \n",
    "\n",
    "    #relação entre nomes e descricões  (é pra isso q essa variavel serve? no original é um datafra esquisito, achei q assim ia ser mais otimizado)   \n",
    "    path_desc = dict(zip(gmt_names,gmt_desc))\n",
    "\n",
    "    return res, path_desc , gmt_names\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# copy pastes e testes aleatorios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "code_folding": [
     5,
     26,
     64,
     155,
     165
    ]
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "\n",
    "\n",
    "def _get_cutoff(deg_list, logFC_col, pvalue_col, min_genes, max_genes):\n",
    "    \n",
    "    dirs = [\"down\", \"up\"]\n",
    "    \n",
    "    res_up = _get_directional_cutoff(\"up\",deg_list, logFC_col, pvalue_col, min_genes, max_genes)\n",
    "    res_down = _get_directional_cutoff(\"down\",deg_list, logFC_col, pvalue_col, min_genes, max_genes)\n",
    "    \n",
    "    res = res_down.merge(res_up,on =\"TopCut\", how=\"outer\" , suffixes = (\"_down\",\"_up\"))\n",
    "    \n",
    "    \n",
    "    res[\"minimum_log2fc_combined\"] = res[['minimum_log2fc_down','minimum_log2fc_up']].min(axis=1)\n",
    "    res[\"minimum_MinuslogP_combined\"] = res[['minimum_MinuslogP_down','minimum_MinuslogP_up']].min(axis=1) \n",
    "    res[\"minimum_Pi_combined\"] = res[['minimum_Pi_down','minimum_Pi_up']].min(axis=1)\n",
    "    \n",
    "    \n",
    "    return res\n",
    "\n",
    "\n",
    "# In[58]:\n",
    "\n",
    "\n",
    "def _get_directional_cutoff(direction,deg_list, logFC_col, pvalue_col, min_genes, max_genes):\n",
    "    if (direction == \"down\"):\n",
    "        ascending = True # no original, decreasing = False\n",
    "    else:\n",
    "        ascending = False\n",
    "            \n",
    "    #pega o deg_list e ordena de maneira decrescente ou crescente usando o logFC_col como chave\n",
    "    # ai ele pega só as n=max genes primeiras linhas e retorna os valores de logFC\n",
    "    top = deg_list.sort_values(by = logFC_col, ascending = ascending)[[logFC_col , pvalue_col]]\n",
    "    top = top[:max_genes]\n",
    "    \n",
    "    top[\"pi_value\"] = top[logFC_col].apply(abs) * (- top[pvalue_col].apply(np.log10))\n",
    "    top = top.sort_values(by = \"pi_value\" , ascending = False)\n",
    "    df = pd.DataFrame(columns = [\"minimum_log2fc\",\"minimum_MinuslogP\",\"minimum_Pi\", \"TopCut\"])\n",
    "    rows = []\n",
    "    for i in range(min_genes, max_genes,50):\n",
    "        top_genes = top.iloc[0:i]\n",
    "        minFC = min(abs(top_genes[logFC_col]))\n",
    "        maxP = max(top_genes[pvalue_col])\n",
    "        minP = - np.log10(maxP)\n",
    "        \n",
    "        minPi = min(top_genes[\"pi_value\"])\n",
    "        \n",
    "        ##### ja foi ordenado, entao posso so pegar o elemento especifico ao invez de procurar o elemento de novo\n",
    " #       minPi = min(top_genes.iloc[i,3])##### essa passagem n faz sentido\n",
    "\n",
    "        row = {\"minimum_log2fc\":minFC, \"minimum_MinuslogP\": minP , \"minimum_Pi\":minPi,\"TopCut\":i}\n",
    "        rows.append(row)\n",
    "    df = pd.DataFrame(rows)\n",
    "    df.set_index(\"TopCut\")\n",
    "    return df\n",
    "\n",
    "\n",
    "# # \\_get_pathway\n",
    "\n",
    "# In[60]:\n",
    "\n",
    "\n",
    "def _get_pathway(merge_p, term2gene, all_genes, deg_list,gene_col, logFC_col, pvalue_col, direction, min_genes, max_genes, p_cut):\n",
    "   \n",
    "    top = get_top(direction, deg_list, max_genes, logFC_col)\n",
    "    \n",
    "    top[\"pi_value\"] = top[logFC_col].apply(abs) * (- top[pvalue_col].apply(np.log10))\n",
    "    top = top.sort_values(by = \"pi_value\", ascending =False).reset_index(drop = True)\n",
    "    \n",
    "      \n",
    "    pathGs = []  #melhorar isso\n",
    "    for i in range(min_genes , max_genes , 50):\n",
    "        top_genes = top.loc[0:i,gene_col].astype(str)\n",
    "        pathG = _run_enrich(top_genes, all_genes, gmt_file)\n",
    "        pathG.columns = [ \"term\" , str(i)]\n",
    "        pathG = pathG.set_index(\"term\",drop=True)\n",
    "        pathGs.append(pathG)\n",
    "    merge_p = pd.concat(pathGs, axis=1, join = \"outer\")\n",
    "    merge_p.fillna(1.0) # acho q n eh mais necessario, ORA faz sozinho\n",
    "    \n",
    "    merge_p2 = ( merge_p.apply(np.log10) )*(-1)\n",
    "    \n",
    "    path_cut_p = np.log10(p_cut)*(-1)\n",
    "    \n",
    "    df = summarizes_ORA_information(merge_p2, path_cut_p,direction)\n",
    "    merge_p2 = pd.concat([df, merge_p2], axis=1)    \n",
    "\n",
    "    \n",
    "    merge_p2 = merge_p2.sort_values(by = \"FirstTopCut_significant_\" + direction , ascending = False)\n",
    "    merge_p2 = merge_p2.drop(labels = [\"TopCut_highestMinuslogP_\" + direction ,\n",
    "                  \"maximum_MinuslogP_\" + direction ,\n",
    "                  \"sum_MinuslogP_\" + direction ,\n",
    "                  \"times_significant_\" + direction  ,\n",
    "                  \"FirstTopCut_significant_\" + direction , \n",
    "                  \"PEBBA_score_\" + direction], axis =1 )\n",
    "    \n",
    "    #refatorar toda essa nojeira legada\n",
    "    \n",
    "    return  df , merge_p2\n",
    "    \n",
    "\n",
    "\n",
    "# In[61]:\n",
    "\n",
    "\n",
    "def get_top(direction, deg_list, max_genes, logFC_col):\n",
    "    \n",
    "    if(direction == \"up\"):\n",
    "        top = deg_list.sort_values(by = logFC_col, ascending = False).head(n=max_genes)\n",
    "    elif(direction ==\"down\"):\n",
    "        top = deg_list.sort_values(by= logFC_col, ascending = True).head(n=max_genes)\n",
    "    elif(direction ==\"any\"):\n",
    "        deg_list[logFC_col] = deg_list[logFC_col].astype(np.float64) \n",
    "        deg_list[logFC_col] = deg_list[logFC_col].abs()\n",
    "        top = deg_list.sort_values(by = logFC_col, ascending = True).head(n=max_genes)\n",
    "    else:\n",
    "        sys.exit(\"Invalid direction argument\")\n",
    "    return top\n",
    "\n",
    "\n",
    "# In[62]:\n",
    "\n",
    "\n",
    "def summarizes_ORA_information(merge_p2, path_cut_p, direction) :\n",
    "\n",
    "\n",
    "    NG = merge_p2.idxmax(axis = 1) # O recorte de genes q apresentou o maior p valor possui NG genes\n",
    "    NG = NG.astype(np.int64)\n",
    "    p_max = merge_p2.max(axis = 1)\n",
    "    p_sum = merge_p2.sum(axis = 1)\n",
    "    \n",
    "    num_columns_merge_p2 = merge_p2.shape[1]\n",
    "    how_many_pathways_above_cut = calculate_how_many_pathways_above_cut(merge_p2,path_cut_p,axis =1)\n",
    "     \n",
    "    times = how_many_pathways_above_cut / num_columns_merge_p2\n",
    "    \n",
    "    ES3 = (1 - np.exp(- p_max) / (1 + (0.1 * np.sqrt(NG)) ) )\n",
    "   \n",
    "    first = merge_p2.apply(first_column_above_path_cut_p , axis = 1, path_cut_p=path_cut_p )\n",
    "    first = first.apply(lambda x: merge_p2.columns[x] if x !=0 else 0 )\n",
    " \n",
    "    dicionario = {\"TopCut_highestMinuslogP_\" + direction : NG,\n",
    "                  \"maximum_MinuslogP_\" + direction : p_max ,\n",
    "                  \"sum_MinuslogP_\" + direction : p_sum,\n",
    "                  \"times_significant_\" + direction : times ,\n",
    "                  \"FirstTopCut_significant_\" + direction : first, \n",
    "                  \"PEBBA_score_\" + direction : ES3}\n",
    "    \n",
    "    df = pd.DataFrame(dicionario)\n",
    "    df[\"FirstTopCut_significant_\" + direction] = df[\"FirstTopCut_significant_\" + direction].astype(np.int64)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def _run_enrich(top_genes, all_genes, gmt_file):\n",
    "    term2gene = GMTUtils.parse_gmt_file(gmt_file)\n",
    "    df = ORA.run(top_genes, all_genes, term2gene).df\n",
    "    df = df[[\"name\", \"fdr\"]]\n",
    "    return df   \n",
    "\n",
    "\n",
    "# In[64]:\n",
    "\n",
    "\n",
    "def first_column_above_path_cut_p(row, path_cut_p):\n",
    "    for cont , element in enumerate(row):\n",
    "        if element > path_cut_p:\n",
    "            return cont\n",
    "    \n",
    "    return 0\n",
    "\n",
    "\n",
    "# In[65]:\n",
    "\n",
    "\n",
    "def calculate_how_many_pathways_above_cut(df, path_cut_p,axis):\n",
    "    f = lambda x: x > path_cut_p\n",
    "    how_many_pathways_above_cut =  df.apply(f,axis=1).sum(axis=axis)\n",
    "    return how_many_pathways_above_cut   \n",
    "\n",
    "# # \\_cutoff_path\n",
    "# In[59]:\n",
    "\n",
    "def _cutoff_path(path_table, p_cut, direction):\n",
    "    \n",
    "    df_index = path_table.columns\n",
    "    df = pd.DataFrame()\n",
    "    df[\"MaxR\"] = path_table.max()\n",
    "    df[\"SumR\"] = path_table.sum()\n",
    "    path_cut_p = np.log10(p_cut) * (-1)\n",
    "    \n",
    "    \n",
    "    #How many pathways above path_cut_p (freq)    \n",
    "    how_many_pathways_above_cut = calculate_how_many_pathways_above_cut(path_table,path_cut_p, axis =0)\n",
    "    n_rows =len(path_table.index) ######\n",
    "    df[\"times\"] = how_many_pathways_above_cut / n_rows\n",
    "    \n",
    "    df.columns = [\"maximum_MinuslogP_\"+ direction,\n",
    "                  \"sum_MinuslogP_\"+ direction,\n",
    "                  \"times_significant_\"+ direction]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting cutoff\n",
      "up\n",
      "Getting Pathways\n",
      "Getting Pathway Cutoff\n",
      "      maximum_MinuslogP_up  sum_MinuslogP_up  times_significant_up\n",
      "100              -0.000000          0.000000              0.000000\n",
      "150               0.017535          0.017535              0.000000\n",
      "200               2.263452          3.326417              0.002448\n",
      "250               2.048301          5.376954              0.003672\n",
      "300               1.717098          5.098998              0.004896\n",
      "350               1.399754          5.614343              0.002448\n",
      "400               1.127487          4.072345              0.002448\n",
      "450               1.065725          5.121371              0.004896\n",
      "500               0.855012          4.057010              0.004896\n",
      "550               0.666252          4.979767              0.000000\n",
      "600               1.007820          9.497538              0.001224\n",
      "650               0.816472         12.637324              0.001224\n",
      "700               0.722450         12.854333              0.006120\n",
      "750               0.610074         19.107426              0.000000\n",
      "800               0.527003         17.766732              0.000000\n",
      "850               0.415415         14.992142              0.000000\n",
      "900               0.393002         15.007870              0.000000\n",
      "950               0.706754         19.758955              0.018360\n",
      "1000              0.541900         13.563162              0.000000\n",
      "1050              0.479175         10.601520              0.000000\n",
      "1100              0.614951         11.652751              0.000000\n",
      "1150              0.520729         12.870232              0.000000\n",
      "1200              0.610857         11.323336              0.000000\n",
      "1250              0.627032         10.579529              0.000000\n",
      "1300              0.536523          7.981042              0.000000\n",
      "1350              0.449918          5.895883              0.000000\n",
      "1400              0.366937          5.817155              0.000000\n",
      "1450              0.481062          7.066604              0.000000\n",
      "down\n",
      "Getting Pathways\n",
      "Getting Pathway Cutoff\n",
      "      maximum_MinuslogP_down  sum_MinuslogP_down  times_significant_down\n",
      "100                 0.249451            3.991499                0.000000\n",
      "150                 2.164649           17.823946                0.006120\n",
      "200                 1.563675           22.819733                0.007344\n",
      "250                 2.310021           24.835885                0.006120\n",
      "300                 3.075275           21.284504                0.002448\n",
      "350                 3.861086           19.529401                0.003672\n",
      "400                 3.418780           24.208689                0.003672\n",
      "450                 3.031967           30.095898                0.003672\n",
      "500                 2.688879           22.790128                0.002448\n",
      "550                 3.540577           28.471335                0.002448\n",
      "600                 4.311219           29.814774                0.003672\n",
      "650                 5.217220           20.826080                0.003672\n",
      "700                 4.827460           42.469071                0.003672\n",
      "750                 5.701966           56.409724                0.006120\n",
      "800                 5.383172           60.629661                0.004896\n",
      "850                 5.085083           44.050194                0.004896\n",
      "900                 4.805326           46.547139                0.004896\n",
      "950                 4.541919           59.969474                0.004896\n",
      "1000                4.293182           50.592253                0.004896\n",
      "1050                4.057685           35.789123                0.004896\n",
      "1100                3.834198           40.703966                0.004896\n",
      "1150                3.621657           47.766894                0.004896\n",
      "1200                3.419132           52.096578                0.004896\n",
      "1250                4.242097           47.431068                0.004896\n",
      "1300                4.038386           37.333860                0.004896\n",
      "1350                3.843174           51.691399                0.007344\n",
      "1400                3.655844           54.647875                0.006120\n",
      "1450                3.475848           62.107061                0.006120\n",
      "any\n",
      "Getting Pathways\n",
      "Getting Pathway Cutoff\n",
      "      maximum_MinuslogP_any  sum_MinuslogP_any  times_significant_any\n",
      "100                3.389492         238.498965               0.159119\n",
      "150                3.067155         198.977259               0.162791\n",
      "200                2.045718         184.647482               0.132191\n",
      "250                2.100024         204.120796               0.093023\n",
      "300                2.201839         176.994404               0.101591\n",
      "350                2.334246         155.347760               0.069767\n",
      "400                3.261630         185.688216               0.090575\n",
      "450                2.657481         159.459127               0.055080\n",
      "500                2.131044         226.230160               0.151775\n",
      "550                3.031144         275.611594               0.220318\n",
      "600                3.231429         253.201576               0.188494\n",
      "650                3.439064         250.093566               0.159119\n",
      "700                3.653269         255.193712               0.189718\n",
      "750                3.873482         230.379706               0.148103\n",
      "800                4.802096         242.898404               0.183599\n",
      "850                4.330410         229.543981               0.160343\n",
      "900                3.892996         206.485365               0.052632\n",
      "950                4.134261         190.723252               0.045288\n",
      "1000               3.730607         179.433960               0.050184\n",
      "1050               3.978889         169.253674               0.047736\n",
      "1100               3.602527         187.506541               0.069767\n",
      "1150               3.248550         176.941498               0.061200\n",
      "1200               3.501925         163.572583               0.051408\n",
      "1250               3.758891         151.617755               0.037944\n",
      "1300               4.019565         167.342589               0.035496\n",
      "1350               4.907279         162.881363               0.028152\n",
      "1400               5.830129         177.740249               0.039168\n",
      "1450               6.111915         204.659262               0.044064\n",
      "Saving heatmaps\n"
     ]
    }
   ],
   "source": [
    "pebba(file_in , gmt_file, force=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coisas a checar proxima vez:\n",
    "## GMTutils, refatorar tudo isso\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
