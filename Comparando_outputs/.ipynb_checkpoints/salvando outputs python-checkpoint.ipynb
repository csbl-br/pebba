{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pypathway import ORA, GMTUtils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "##funcoes###3\n",
    "\n",
    "\n",
    "def validates_inputs(min_genes,max_genes,p_cut):\n",
    "\n",
    "    if(min_genes < 50 or min_genes > 2900):\n",
    "        sys.exit(\"Variable min_genes must be between 50 and 2900 genes\")\n",
    "          \n",
    "    if(max_genes < 100 or max_genes > 3000):\n",
    "        sys.exit(\"Variable max_genes must be between 100 and 3000 genes\")  \n",
    "    \n",
    "    if(p_cut < 0.00001 or p_cut > 1):\n",
    "        sys.exit(\"Variable p_cut must be between 0.00001 and 1\")       \n",
    "\n",
    "def create_results_directory(results_dir,force):\n",
    "    results_dir = os.path.abspath(results_dir)\n",
    "    if not os.path.exists(results_dir): \n",
    "        os.makedirs(\"Results/Tables\") \n",
    "        os.makedirs(\"Results/Heatmaps\")      \n",
    "    else:    \n",
    "        if( not force): \n",
    "            sys.exit(\"Stopping analysis: \", results_dir, \" already exists! Use force=True to overwrite.\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pypathway import ORA, GMTUtils\n",
    "\n",
    "\n",
    "\n",
    "def _get_directional_cutoff(direction,deg_list, logFC_col, pvalue_col, min_genes, max_genes):\n",
    "    if (direction == \"down\"):\n",
    "        ascending = True # no original, decreasing = False\n",
    "    else:\n",
    "        ascending = False\n",
    "            \n",
    "    #pega o deg_list e ordena de maneira decrescente ou crescente usando o logFC_col como chave\n",
    "    # ai ele pega só as n=max genes primeiras linhas e retorna os valores de logFC\n",
    "    top = deg_list.sort_values(by = logFC_col, ascending = ascending)[[logFC_col , pvalue_col]]\n",
    "    top = top[:max_genes]\n",
    "    \n",
    "    top[\"pi_value\"] = abs(top[logFC_col]) *(-1)* ( np.log10(top[pvalue_col]))\n",
    "    top = top.sort_values(by = \"pi_value\" , ascending = False)\n",
    "    df = pd.DataFrame(columns = [\"minimum_log2fc\",\"minimum_MinuslogP\",\"minimum_Pi\", \"TopCut\"])\n",
    "    rows = []\n",
    "    for i in range(min_genes, max_genes+1 ,50):  # max_genes +1 to include the number max_genes in the range\n",
    "        top_genes = top.iloc[0:i]\n",
    "        minFC = min(abs(top_genes[logFC_col]))\n",
    "        maxP = max(top_genes[pvalue_col])\n",
    "        minP = - np.log10(maxP)\n",
    "        \n",
    "        minPi = min(top_genes[\"pi_value\"])\n",
    "        \n",
    "        ##### ja foi ordenado, entao posso so pegar o elemento especifico ao invez de procurar o elemento de novo\n",
    " #       minPi = min(top_genes.iloc[i,3])##### essa passagem do original n faz sentido\n",
    "\n",
    "        row = {\"minimum_log2fc\":minFC, \"minimum_MinuslogP\": minP , \"minimum_Pi\":minPi,\"TopCut\":i}\n",
    "        rows.append(row)\n",
    "    df = pd.DataFrame(rows)\n",
    "    df.set_index(\"TopCut\")\n",
    "    return df\n",
    "\n",
    "def _get_cutoff(deg_list, logFC_col, pvalue_col, min_genes, max_genes):\n",
    "    \n",
    "    dirs = [\"down\", \"up\"]\n",
    "    \n",
    "    res_up = _get_directional_cutoff(\"up\",deg_list, logFC_col, pvalue_col, min_genes, max_genes)\n",
    "    res_down = _get_directional_cutoff(\"down\",deg_list, logFC_col, pvalue_col, min_genes, max_genes)\n",
    "    \n",
    "    res = res_down.merge(res_up,on =\"TopCut\", how=\"outer\" , suffixes = (\"_down\",\"_up\"))\n",
    "    \n",
    "    \n",
    "    res[\"minimum_log2fc_combined\"] = res[['minimum_log2fc_down','minimum_log2fc_up']].min(axis=1)\n",
    "    res[\"minimum_MinuslogP_combined\"] = res[['minimum_MinuslogP_down','minimum_MinuslogP_up']].min(axis=1) \n",
    "    res[\"minimum_Pi_combined\"] = res[['minimum_Pi_down','minimum_Pi_up']].min(axis=1)\n",
    "    \n",
    "    \n",
    "    return res\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###############################################################################################################################################\n",
    "\n",
    "\n",
    "def _cutoff_path(path_table, p_cut, direction):\n",
    "    \n",
    "    df_index = path_table.columns\n",
    "    df = pd.DataFrame()\n",
    "    df[\"MaxR\"] = path_table.max()\n",
    "    df[\"SumR\"] = path_table.sum()\n",
    "    path_cut_p = np.log10(p_cut) * (-1)\n",
    "    \n",
    "    \n",
    "    #How many pathways above path_cut_p (freq)    \n",
    "    how_many_pathways_above_cut = calculate_how_many_pathways_above_cut(path_table,path_cut_p, axis =0)\n",
    "    n_rows =len(path_table.index) ######\n",
    "    df[\"times\"] = how_many_pathways_above_cut / n_rows\n",
    "    \n",
    "    df.columns = [\"maximum_MinuslogP_\"+ direction,\n",
    "                  \"sum_MinuslogP_\"+ direction,\n",
    "                  \"times_significant_\"+ direction]\n",
    "    return df\n",
    "\n",
    "\n",
    "###############################################################################################################################################\n",
    "\n",
    "\n",
    "def _get_pathway(merge_p, term2gene, all_genes, deg_list,gene_col, logFC_col, pvalue_col, direction, min_genes, max_genes, p_cut):\n",
    "   \n",
    "    top = get_top(direction, deg_list, max_genes, logFC_col)\n",
    "    \n",
    "    top[\"pi_value\"] = top[logFC_col].apply(abs) * (- top[pvalue_col].apply(np.log10))\n",
    "    top = top.sort_values(by = \"pi_value\", ascending =False).reset_index(drop = True)\n",
    "    \n",
    "      \n",
    "    pathGs = []  #melhorar isso\n",
    "    for i in range(min_genes, max_genes+1 ,50):  # max_genes +1 to include the number max_genes in the range\n",
    "        top_genes = top.loc[0:i,gene_col].astype(str)\n",
    "        pathG = _run_enrich(top_genes, all_genes, gmt_file)\n",
    "        pathG.columns = [ \"term\" , str(i)]\n",
    "        pathG = pathG.set_index(\"term\",drop=True)\n",
    "        pathGs.append(pathG)\n",
    "    merge_p = pd.concat(pathGs, axis=1, join = \"outer\")\n",
    "    merge_p.fillna(1.0) # acho q n eh mais necessario, ORA faz sozinho\n",
    "    \n",
    "    merge_p2 = ( merge_p.apply(np.log10) )*(-1)\n",
    "    \n",
    "    path_cut_p = np.log10(p_cut)*(-1)\n",
    "    \n",
    "    df = summarizes_ORA_information(merge_p2, path_cut_p,direction)\n",
    "    merge_p2 = pd.concat([df, merge_p2], axis=1)    \n",
    "\n",
    "    \n",
    "    merge_p2 = merge_p2.sort_values(by = \"FirstTopCut_significant_\" + direction , ascending = False)\n",
    "    merge_p2 = merge_p2.drop(labels = [\"TopCut_highestMinuslogP_\" + direction ,\n",
    "                  \"maximum_MinuslogP_\" + direction ,\n",
    "                  \"sum_MinuslogP_\" + direction ,\n",
    "                  \"times_significant_\" + direction  ,\n",
    "                  \"FirstTopCut_significant_\" + direction , \n",
    "                  \"PEBBA_score_\" + direction], axis =1 )\n",
    "    \n",
    "    #refatorar toda essa nojeira legada\n",
    "    \n",
    "    return  df , merge_p2\n",
    "    \n",
    "\n",
    "def get_top(direction, deg_list, max_genes, logFC_col):\n",
    "    \n",
    "    if(direction == \"up\"):\n",
    "        top = deg_list.sort_values(by = logFC_col, ascending = False).head(n=max_genes)\n",
    "    elif(direction ==\"down\"):\n",
    "        top = deg_list.sort_values(by= logFC_col, ascending = True).head(n=max_genes)\n",
    "    elif(direction ==\"any\"):\n",
    "        deg_list[logFC_col] = deg_list[logFC_col].astype(np.float64) \n",
    "        deg_list[logFC_col] = deg_list[logFC_col].abs()\n",
    "        top = deg_list.sort_values(by = logFC_col, ascending = True).head(n=max_genes)\n",
    "    else:\n",
    "        sys.exit(\"Invalid direction argument\")\n",
    "    return top\n",
    "\n",
    "\n",
    "def summarizes_ORA_information(merge_p2, path_cut_p, direction) :\n",
    "\n",
    "\n",
    "    NG = merge_p2.idxmax(axis = 1) # O recorte de genes q apresentou o maior p valor possui NG genes\n",
    "    NG = NG.astype(np.int64)\n",
    "    p_max = merge_p2.max(axis = 1)\n",
    "    p_sum = merge_p2.sum(axis = 1)\n",
    "    \n",
    "    num_columns_merge_p2 = merge_p2.shape[1]\n",
    "    how_many_pathways_above_cut = calculate_how_many_pathways_above_cut(merge_p2,path_cut_p,axis =1)\n",
    "     \n",
    "    times = how_many_pathways_above_cut / num_columns_merge_p2\n",
    "    \n",
    "    ES3 = (1 - np.exp(- p_max) / (1 + (0.1 * np.sqrt(NG)) ) )\n",
    "   \n",
    "    first = merge_p2.apply(first_column_above_path_cut_p , axis = 1, path_cut_p=path_cut_p )\n",
    "    first = first.apply(lambda x: merge_p2.columns[x] if x !=0 else 0 )\n",
    " \n",
    "    dicionario = {\"TopCut_highestMinuslogP_\" + direction : NG,\n",
    "                  \"maximum_MinuslogP_\" + direction : p_max ,\n",
    "                  \"sum_MinuslogP_\" + direction : p_sum,\n",
    "                  \"times_significant_\" + direction : times ,\n",
    "                  \"FirstTopCut_significant_\" + direction : first, \n",
    "                  \"PEBBA_score_\" + direction : ES3}\n",
    "    \n",
    "    df = pd.DataFrame(dicionario)\n",
    "    df[\"FirstTopCut_significant_\" + direction] = df[\"FirstTopCut_significant_\" + direction].astype(np.int64)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def _run_enrich(top_genes, all_genes, gmt_file):\n",
    "    term2gene = GMTUtils.parse_gmt_file(gmt_file)\n",
    "    df = ORA.run(top_genes, all_genes, term2gene).df\n",
    "    df = df[[\"name\", \"fdr\"]]\n",
    "    return df   \n",
    "\n",
    "\n",
    "def first_column_above_path_cut_p(row, path_cut_p):\n",
    "    for cont , element in enumerate(row):\n",
    "        if element > path_cut_p:\n",
    "            return cont\n",
    "    \n",
    "    return 0\n",
    "\n",
    "\n",
    "def calculate_how_many_pathways_above_cut(df, path_cut_p,axis):\n",
    "    f = lambda x: x > path_cut_p\n",
    "    how_many_pathways_above_cut =  df.apply(f,axis=1).sum(axis=axis)\n",
    "    return how_many_pathways_above_cut   \n",
    "\n",
    "###############################################################################################################################################\n",
    "# ## backup\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "#\n",
    "# def calculate_how_many_pathways_above_cut(df, path_cut_p):\n",
    "#     f = lambda x: x > path_cut_p\n",
    "#     how_many_pathways_above_cut =  df.apply(f,axis=1).sum(axis=1)\n",
    "#     return how_many_pathways_above_cut   \n",
    "\n",
    "# # # \\_cutoff_path\n",
    "# # In[59]:\n",
    "\n",
    "# def _cutoff_path(path_table, p_cut, direction):\n",
    "    \n",
    "#     df_index = path_table.columns\n",
    "#     df = pd.DataFrame()\n",
    "#     df[\"MaxR\"] = path_table.max()\n",
    "#     df[\"SumR\"] = path_table.sum()\n",
    "#     path_cut_p = np.log10(p_cut) * (-1)\n",
    "    \n",
    "    \n",
    "#     #How many pathways above path_cut_p (freq)    \n",
    "#     how_many_pathways_above_cut = calculate_how_many_pathways_above_cut(path_table,path_cut_p)\n",
    "#     n_rows =len(path_table.index) ######\n",
    "#     print(how_many_pathways_above_cut)\n",
    "#     df[\"times\"] = how_many_pathways_above_cut / n_rows\n",
    "    \n",
    "#     df.columns = [\"maximum_MinuslogP_\"+ direction,\n",
    "#                   \"sum_MinuslogP_\"+ direction,\n",
    "#                   \"times_significant_\"+ direction]\n",
    "    \n",
    "#     df.set_index(df_index) #drop True inutil (?)\n",
    "# #     print(df)\n",
    "#     return df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def summarizes_ORA_information(merge_p2, path_cut_p, direction) :\n",
    "\n",
    "\n",
    "#     NG = merge_p2.idxmax(axis = 1) # O recorte de genes q apresentou o maior p valor possui NG genes\n",
    "#     NG = NG.astype(np.int64)\n",
    "#     p_max = merge_p2.max(axis = 1)\n",
    "#     p_sum = merge_p2.sum(axis = 1)\n",
    "    \n",
    "#     num_columns_merge_p2 = merge_p2.shape[1]\n",
    "#     how_many_pathways_above_cut = calculate_how_many_pathways_above_cut(merge_p2,path_cut_p)\n",
    "     \n",
    "#     times = how_many_pathways_above_cut / num_columns_merge_p2\n",
    "    \n",
    "#     ES3 = (1 - np.exp(- p_max) / (1 + (0.1 * np.sqrt(NG)) ) )\n",
    "   \n",
    "#     first = merge_p2.apply(first_column_above_path_cut_p , axis = 1, path_cut_p=path_cut_p )\n",
    "#     first = first.apply(lambda x: merge_p2.columns[x] if x !=0 else 0 )\n",
    " \n",
    "#     dicionario = {\"TopCut_highestMinuslogP_\" + direction : NG,\n",
    "#                   \"maximum_MinuslogP_\" + direction : p_max ,\n",
    "#                   \"sum_MinuslogP_\" + direction : p_sum,\n",
    "#                   \"times_significant_\" + direction : times ,\n",
    "#                   \"FirstTopCut_significant_\" + direction : first, \n",
    "#                   \"PEBBA_score_\" + direction : ES3}\n",
    "    \n",
    "#     df = pd.DataFrame(dicionario)\n",
    "#     df[\"FirstTopCut_significant_\" + direction] = df[\"FirstTopCut_significant_\" + direction].astype(np.int64)\n",
    "    \n",
    "#     return df\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def read_gmt_hier(file_name):\n",
    "    '''\n",
    "    file_name string -> dataframe and dictionary\n",
    "    \n",
    "    Reads .gmt file and returns a Pandas DataFrame and a dictionary with the information of the gmt file in a format ready to be used.\n",
    "    \n",
    "    '''\n",
    "    gmt_names = []\n",
    "    gmt_desc  = []\n",
    "    gmt_genes = []\n",
    "    res =pd.DataFrame()\n",
    "\n",
    "    with open(file_name, 'r') as f:\n",
    "        # separar cada elemento separado por tab e guardar eles\n",
    "        for line in f:\n",
    "            gmt_names.append(line.split(\"\\t\")[0])\n",
    "            gmt_desc.append(line.split(\"\\t\")[1])\n",
    "            gmt_genes.append(line.split(\"\\t\")[2:])\n",
    "\n",
    "    for i in range(len(gmt_genes)) :\n",
    "\n",
    "        # apagar \\n presente no ultimo gene de cada lista (artefato da leitura do arquivo)\n",
    "        gmt_genes[i][-1] = gmt_genes[i][-1].replace(\"\\n\", \"\")\n",
    "\n",
    "        # Poem na forma de um dataframe, cada linha um gene e suas informações relativas \n",
    "        temp= pd.DataFrame({'term': [gmt_names[i]]*len(gmt_genes[i]), 'hier':  [gmt_desc[i]]*len(gmt_genes[i]), 'gene' : gmt_genes[i] })\n",
    "        res = pd.concat([res,temp])\n",
    "\n",
    "    # reseta o indice\n",
    "    res = res.reset_index(drop=True)    \n",
    "\n",
    "    #relação entre nomes e descricões  (é pra isso q essa variavel serve? no original é um datafra esquisito, achei q assim ia ser mais otimizado)   \n",
    "    path_desc = dict(zip(gmt_names,gmt_desc))\n",
    "\n",
    "    return res, path_desc , gmt_names\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def pebba(file_in, \n",
    "          gmt_file, \n",
    "          gene_col=\"Gene.symbol\",\n",
    "          logFC_col=\"logFC\",\n",
    "          pvalue_col=\"P.Value\",\n",
    "          min_genes=100,\n",
    "          max_genes=1500,\n",
    "          p_cut=0.2,\n",
    "          verbose=True,\n",
    "          analysis_name= None, \n",
    "          results_dir=\"Results\",\n",
    "          force=False):\n",
    "\n",
    "    validates_inputs(min_genes,max_genes,p_cut)\n",
    "\n",
    "    create_results_directory(results_dir,force)\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    ## Get information from all unique terms\n",
    "    \n",
    "    term2gene , path_desc , merge_p  = read_gmt_hier(gmt_file) #utils.read_gmt_hier(gmt_file)    \n",
    "\n",
    "# alterei funcao pra retornar o merge_p, \n",
    "# ta retornando no formato de vetor mas talvez tenha q mudar para dataframe ou serie\n",
    "    \n",
    "    \n",
    "    \n",
    "    if( isinstance(file_in , str)):\n",
    "        deg_list = pd.read_csv(file_in,  sep = \"\\t\")#header true no original, so tirei o header pra o python inferir\n",
    "        if(analysis_name is None):\n",
    "            analysis_name =   os.path.splitext(os.path.basename(file_in) )[0] # pega o basename e tira a extensao\n",
    "     \n",
    "    elif(isinstance(file_in , pd.DataFrame)):\n",
    "        deg_list = file_in\n",
    "    \n",
    "\n",
    "    if(analysis_name is None):\n",
    "        analysis_name = \"PEBBA_analysis\"\n",
    "    \n",
    "    ## Remove rows that do not have a valid gene symbol\n",
    "    deg_list = deg_list.dropna()\n",
    "    ## Get background genes as a character vector\n",
    "    ## Empty values (non-annotated genes) will be removed\n",
    "    all_genes = deg_list[\"Gene.symbol\"] # passar pra lista?\n",
    "    \n",
    "    # Get cutoff values -------------------------------------------------------\n",
    "    if(verbose):\n",
    "        print(\"Getting cutoff\") # no original era message(), posso usar um print?\n",
    "        \n",
    "    table_cut = _get_cutoff(deg_list, logFC_col, pvalue_col, min_genes, max_genes)\n",
    "   \n",
    "    ###########################\n",
    "    table_cut.to_csv(\"outputs_py/table_cut_py.csv\")\n",
    "    ###########################\n",
    "    \n",
    "    directions = [\"up\", \"down\" , \"any\"]\n",
    "    \n",
    "    cut_paths =[]\n",
    "    dfs = []\n",
    "    paths = []\n",
    "    for direction in directions:\n",
    "        if (verbose):\n",
    "            print(direction + \"\\nGetting Pathways\")\n",
    "        df , path = _get_pathway(merge_p, term2gene, all_genes,\n",
    "                            deg_list, gene_col, logFC_col,\n",
    "                            pvalue_col, direction,\n",
    "                            min_genes, max_genes, p_cut)\n",
    "        if (verbose):\n",
    "            print(\"Getting Pathway Cutoff\")\n",
    "        \n",
    "        cut_path = _cutoff_path(path, p_cut, direction)\n",
    "        \n",
    "        cut_path.to_csv(\"outputs_py/cut_path_py_\"+ direction + \".csv\")\n",
    "        df.to_csv(\"outputs_py/df_py_\"+ direction + \".csv\")\n",
    "        path.to_csv(\"path_py_\" + direction + \".csv\")\n",
    "        \n",
    "        cut_paths.append(cut_path)\n",
    "        dfs.append(df)\n",
    "        paths.append(path)\n",
    "    \n",
    "    \n",
    "    ## Save heatmaps\n",
    "    if(verbose):\n",
    "        print(\"Saving heatmaps\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting cutoff\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-c9cdb8532771>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfile_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"../data/GSE49757_Septic_vs_Healthy.txt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mgmt_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"../data/Reactome_2016_15and100Genes.gmt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mpebba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_in\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgmt_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mforce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-25-408dbf11929e>\u001b[0m in \u001b[0;36mpebba\u001b[0;34m(file_in, gmt_file, gene_col, logFC_col, pvalue_col, min_genes, max_genes, p_cut, verbose, analysis_name, results_dir, force)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Getting cutoff\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# no original era message(), posso usar um print?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0mtable_cut\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_cutoff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeg_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogFC_col\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpvalue_col\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_genes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_genes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;31m###########################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-812a65764144>\u001b[0m in \u001b[0;36m_get_cutoff\u001b[0;34m(deg_list, logFC_col, pvalue_col, min_genes, max_genes)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"minimum_log2fc_combined\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'minimum_log2fc_down'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'minimum_log2fc_up'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"minimum_MinuslogP_combined\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'minimum_MinuslogP_down'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'minimum_MinuslogP_up'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"minimum_Pi_combined\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'minimum_Pi_down'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'minimum_Pi_up'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2680\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2681\u001b[0m             \u001b[0;31m# either boolean or fancy integer index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2682\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2683\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2684\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_array\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2724\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_take\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2725\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2726\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2727\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_take\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[0;34m(self, obj, axis, is_setter)\u001b[0m\n\u001b[1;32m   1312\u001b[0m                 \u001b[0;31m# unique index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1313\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1314\u001b[0;31m                     \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m                 \u001b[0;31m# non-unique (dups)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_indexer\u001b[0;34m(self, target, method, limit, tolerance)\u001b[0m\n\u001b[1;32m   3220\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3221\u001b[0m         \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmissing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclean_reindex_fill_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3222\u001b[0;31m         \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3223\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3224\u001b[0m             \u001b[0mtolerance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_tolerance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_ensure_index\u001b[0;34m(index_like, copy)\u001b[0m\n\u001b[1;32m   4972\u001b[0m             \u001b[0mindex_like\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_like\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4973\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4974\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_like\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4975\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4976\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls, data, dtype, copy, name, fastpath, tupleize_cols, **kwargs)\u001b[0m\n\u001b[1;32m    379\u001b[0m                 \u001b[0msubarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'object'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m                 \u001b[0msubarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_asarray_tuplesafe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m             \u001b[0;31m# _asarray_tuplesafe does not always copy underlying data,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/pandas/core/common.py\u001b[0m in \u001b[0;36m_asarray_tuplesafe\u001b[0;34m(values, dtype)\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mconstruct_1d_object_array_from_listlike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m     \"\"\"\n\u001b[0;32m--> 501\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "file_in = \"../data/GSE49757_Septic_vs_Healthy.txt\"\n",
    "gmt_file = \"../data/Reactome_2016_15and100Genes.gmt\"\n",
    "pebba(file_in,gmt_file,force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
